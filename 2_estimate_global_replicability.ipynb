{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sliu/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# fdr multiple testing correction\n",
    "from statsmodels.stats import multitest\n",
    "\n",
    "def fdr_correction(P):\n",
    "    size = P.shape\n",
    "    temp_p = P.flatten()\n",
    "    Ps = multitest.multipletests(temp_p,alpha=0.05,method='fdr_bh')\n",
    "    P_corrected = Ps[1].reshape(size)\n",
    "\n",
    "    return P_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of calculating Jaccard index\n",
    "from sklearn.metrics import confusion_matrix,jaccard_score\n",
    "def Jaccard_index(data1,data2,t=None):\n",
    "    s = data1.shape\n",
    "    odata1 = np.zeros((s[0],2))\n",
    "    for i in range(s[0]):\n",
    "        tmp_l = []\n",
    "        for j in range(s[1]):\n",
    "            corr_map1 = data1[i,j,:,:]\n",
    "            corr_map2 = data2[i,j,:,:] \n",
    "            # the thresholds to select significant brain associations\n",
    "            if t == 'fdr':\n",
    "                correct_P1 = fdr_correction(corr_map1[:,1])\n",
    "                correct_P2 = fdr_correction(corr_map2[:,1])\n",
    "                \n",
    "                l1 = np.where(correct_P1 < 0.05)[0].tolist()\n",
    "                l2 = np.where(correct_P2 < 0.05)[0].tolist()\n",
    "            elif t == 'bonferroni':\n",
    "                pt = 0.05/s[2]\n",
    "                l1 = np.where(corr_map1[:,1] < pt)[0].tolist()\n",
    "                l2 = np.where(corr_map2[:,1] < pt)[0].tolist()\n",
    "            else:\n",
    "                l1 = np.where(corr_map1[:,1] < float(t))[0].tolist()\n",
    "                l2 = np.where(corr_map2[:,1] < float(t))[0].tolist()\n",
    "                \n",
    "            seqs = np.zeros((s[2],2))\n",
    "            seqs[l1,0] = 1\n",
    "            seqs[l2,1] = 1\n",
    "            if len(l1) == 0 and len(l2) == 0:\n",
    "                confusion_matrix1 = np.zeros((2,2))\n",
    "                confusion_matrix1[0,0] = s[2]\n",
    "            else:\n",
    "                confusion_matrix1 = confusion_matrix(seqs[:,0],seqs[:,1])\n",
    "                \n",
    "            confusion_matrix2 = np.zeros((2,2))\n",
    "            confusion_matrix2[0,0] = (confusion_matrix1[0,0] + confusion_matrix1[0,1])*(confusion_matrix1[0,0] + confusion_matrix1[1,0])\n",
    "            confusion_matrix2[1,1] = (confusion_matrix1[1,1] + confusion_matrix1[0,1])*(confusion_matrix1[1,1] + confusion_matrix1[1,0])\n",
    "            confusion_matrix2[0,1] = (confusion_matrix1[1,1] + confusion_matrix1[0,1])*(confusion_matrix1[0,0] + confusion_matrix1[0,1])\n",
    "            confusion_matrix2[1,0] = (confusion_matrix1[1,1] + confusion_matrix1[1,0])*(confusion_matrix1[0,0] + confusion_matrix1[1,0])\n",
    "            \n",
    "            n1 = confusion_matrix1[1,1] + confusion_matrix1[1,0] + confusion_matrix1[0,1]\n",
    "            if n1 == 0:\n",
    "                S = 0\n",
    "            else:\n",
    "                S = confusion_matrix1[1,1]/ n1\n",
    "            \n",
    "            n2 = confusion_matrix2[1,1] + confusion_matrix2[1,0] + confusion_matrix2[0,1]\n",
    "            if n2 == 0:\n",
    "                ES = 0\n",
    "            else:\n",
    "                ES = confusion_matrix2[1,1]/n2\n",
    "            \n",
    "            dd = (S - ES)/(1-ES)\n",
    "            tmp_l.append(dd)\n",
    "                \n",
    "        odata1[i,0] = np.mean(tmp_l)\n",
    "        odata1[i,1] = np.std(tmp_l)\n",
    "    return odata1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical_analysis_Jaccard: The main function to calculate the Jaccard index\n",
    "### input parameters: file_path, npy_file1, npy_file2, *t*, mytype, output_path\n",
    "**file_path:** The folder that includes the npy files (The bootstrapped correlations)\n",
    "\n",
    "**npy_file1:** The npy file obtained from subsample1\n",
    "\n",
    "**npy_file2:** The npy file obtained from subsample2\n",
    "\n",
    "**t:** The significance thresholds: p<0.05, p<0.01, fdr_p<0.05, fdr_bonferroni<0.05. For example, *t* = '0.05', '0.01','fdr',or 'bonferroni'\n",
    "\n",
    "**mytype:** The imaging type: \"CSA\", \"CT\", or \"FC\"\n",
    "\n",
    "**output_path:** The folder where the results of Jaccard index are saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis_Jaccard(file_path,npy_file1,npy_file2,t,mytype,output_path):\n",
    "    file_path = 'boostrap_correlations/'\n",
    "    files = os.listdir(file_path)\n",
    "    for f in files:\n",
    "        file_path1 = os.path.join(file_path,f) + '/'+ npy_file1\n",
    "        file_path2 = os.path.join(file_path,f) + '/'+ npy_file2\n",
    "        random_data1 = np.load(file_path1)\n",
    "        random_data2 = np.load(file_path2)\n",
    "\n",
    "        reliability = Jaccard_index(random_data1,random_data2,t=t)\n",
    "        if not os.path.exists(output_path+f):\n",
    "            os.mkdir(output_path+f)\n",
    "        file_name = output_path+f+'/'+mytype+'_Jaccard_index_'+t+'.csv'\n",
    "        data = pd.DataFrame(data=reliability)\n",
    "        data.to_csv(file_name,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The significance level is:  0.05\n",
      "The significance level is:  0.01\n",
      "The significance level is:  fdr\n",
      "The significance level is:  bonferroni\n"
     ]
    }
   ],
   "source": [
    "# runing the main function to estimate Jaccard index\n",
    "ts = ['0.05', '0.01','fdr','bonferroni']\n",
    "for t in ts:\n",
    "    print(\"The significance level is: \", t)\n",
    "    statistical_analysis_Jaccard(\"boostrap_correlations/\",\"random_data_CSA1.npy\",\"random_data_CSA2.npy\",\\\n",
    "                         t,\"CSA\",\"Jaccard/\")\n",
    "    statistical_analysis_Jaccard(\"boostrap_correlations/\",\"random_data_CT1.npy\",\"random_data_CT2.npy\",\\\n",
    "                         t,\"CT\",\"Jaccard/\")\n",
    "    statistical_analysis_Jaccard(\"boostrap_correlations/\",\"random_data_FC1.npy\",\"random_data_FC2.npy\",\\\n",
    "                         t,\"FC\",\"Jaccard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of calculating Intraclass Correlation Coefficient\n",
    "import pingouin as pg\n",
    "from scipy import stats\n",
    "\n",
    "def calculate_ICC(data1,data2,t = None):\n",
    "    subsampling_times = data1.shape[0]\n",
    "    random_num = data1.shape[1]\n",
    "    ICC_data = np.zeros((subsampling_times,2)) \n",
    "    t = float(t)\n",
    "    region_num = round(t * data1.shape[2])\n",
    "    for i in range(subsampling_times):\n",
    "        print(i)\n",
    "        temp_icc = []\n",
    "        for j in range(random_num):\n",
    "            \n",
    "            my_targets = []\n",
    "            my_raters = []\n",
    "            my_ratings = []\n",
    "            \n",
    "            tdata1 = data1[i,j,:,:]\n",
    "            tdata2 = data2[i,j,:,:]\n",
    "            zdata1 = stats.zscore(tdata1[:,0])\n",
    "            zdata2 = stats.zscore(tdata2[:,0])\n",
    "            argindexs1 = np.argsort(tdata1[:,1])[:region_num]\n",
    "            tmp1 = zdata1[argindexs1]\n",
    "            tmp2 = zdata2[argindexs1]\n",
    "            \n",
    "\n",
    "            for k in range(region_num):\n",
    "                my_targets.append(k+1)\n",
    "                my_raters.append('A')\n",
    "                my_ratings.append(tmp1[k])\n",
    "  \n",
    "                my_targets.append(k+1)\n",
    "                my_raters.append('B')\n",
    "                my_ratings.append(tmp2[k])\n",
    "        \n",
    "            my_df_data = pd.DataFrame(data=my_targets,columns=['region'])\n",
    "            my_df_data['random_time'] = my_raters\n",
    "            my_df_data['corr'] = my_ratings\n",
    "            # ICC2: A random sample of k raters rate each target. The measure is one of absolute agreement in the ratings.\n",
    "            my_icc = pg.intraclass_corr(data=my_df_data, targets='region', raters='random_time', ratings='corr')['ICC'].values[1]\n",
    "            temp_icc.append(my_icc)\n",
    "    \n",
    "        ICC_data[i,0] = np.mean(temp_icc)\n",
    "        ICC_data[i,1] = np.std(temp_icc)\n",
    "    return ICC_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical_analysis_ICC: The main function to calculate the ICC\n",
    "### input parameters: file_path, npy_file1, npy_file2, *t*, mytype, output_path\n",
    "**file_path:** The folder that includes the npy files (The bootstrapped correlations)\n",
    "\n",
    "**npy_file1:** The npy file obtained from subsample1\n",
    "\n",
    "**npy_file2:** The npy file obtained from subsample2\n",
    "\n",
    "**t:** The proportion of correlations to calculate the ICC: 0.1,0.15,0.2,0.25,0.5,1\n",
    "\n",
    "**mytype:** The imaging type: \"CSA\", \"CT\", or \"FC\"\n",
    "\n",
    "**output_path:** The folder where the results of Jaccard index are saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis_ICC(file_path,npy_file1,npy_file2,t,mytype,output_path):\n",
    "    file_path = 'boostrap_correlations/'\n",
    "    files = os.listdir(file_path)\n",
    "    for f in files:\n",
    "        file_path1 = os.path.join(file_path,f) + '/'+ npy_file1\n",
    "        file_path2 = os.path.join(file_path,f) + '/'+ npy_file2\n",
    "        random_data1 = np.load(file_path1)\n",
    "        random_data2 = np.load(file_path2)\n",
    "        \n",
    "        reliability = calculate_ICC(random_data1,random_data2,t=t)\n",
    "        if not os.path.exists(output_path+f):\n",
    "            os.mkdir(output_path+f)\n",
    "        file_name = output_path+f+'/'+mytype+'_ICC_'+t+'.csv'\n",
    "        data = pd.DataFrame(data=reliability)\n",
    "        data.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runing the main function to estimate ICC\n",
    "ts = ['0.1', '0.15','0.2','0.25','0.5','1']\n",
    "for t in ts:\n",
    "    print(\"The significance level is: \", t)\n",
    "    statistical_analysis_ICC(\"boostrap_correlations/\",\"random_data_CSA1.npy\",\"random_data_CSA2.npy\",\\\n",
    "                         t,\"CSA\",\"ICC/\")\n",
    "    statistical_analysis_ICC(\"boostrap_correlations/\",\"random_data_CT1.npy\",\"random_data_CT2.npy\",\\\n",
    "                         t,\"CT\",\"ICC/\")\n",
    "    statistical_analysis_ICC(\"boostrap_correlations/\",\"random_data_FC1.npy\",\"random_data_FC2.npy\",\\\n",
    "                         t,\"FC\",\"ICC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
