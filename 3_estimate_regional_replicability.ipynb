{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sliu/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# fdr multiple testing correction\n",
    "from statsmodels.stats import multitest\n",
    "\n",
    "def fdr_correction(P):\n",
    "    size = P.shape\n",
    "    temp_p = P.flatten()\n",
    "    Ps = multitest.multipletests(temp_p,alpha=0.05,method='fdr_bh')\n",
    "    P_corrected = Ps[1].reshape(size)\n",
    "\n",
    "    return P_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of calculating regional replicability\n",
    "def estimate_reliability(data1,data2,t=None):\n",
    "    s = data1.shape\n",
    "    odata1 = np.zeros((s[0],s[1],s[2]))\n",
    "    if t == 'fdr':\n",
    "        for i in range(s[0]):\n",
    "            for j in range(s[1]):\n",
    "                corr_map1 = data1[i,j,:,:]\n",
    "                corr_map2 = data2[i,j,:,:]\n",
    "                correct_P1 = fdr_correction(corr_map1[:,1])\n",
    "                correct_P2 = fdr_correction(corr_map2[:,1])\n",
    "\n",
    "                tmp_data = np.zeros((s[2],2))\n",
    "                for k in range(s[2]):\n",
    "                    t1 = corr_map1[k,0]\n",
    "                    t2 = corr_map2[k,0]\n",
    "                    if t1*t2 > 0 and correct_P1[k] < 0.05 and correct_P2[k] < 0.05:\n",
    "                        odata1[i,j,k] = 1\n",
    "    elif t == 'bonferroni':\n",
    "        for i in range(s[0]):\n",
    "            for j in range(s[1]):\n",
    "                corr_map1 = data1[i,j,:,:]\n",
    "                corr_map2 = data2[i,j,:,:]\n",
    "                \n",
    "                tmp_data = np.zeros((s[2],2))\n",
    "                tp = 0.05/s[2]\n",
    "                for k in range(s[2]):\n",
    "                    t1 = corr_map1[k,0]\n",
    "                    t2 = corr_map2[k,0]\n",
    "                    if t1*t2 > 0 and corr_map1[k,1] < tp and corr_map2[k,1] < tp:\n",
    "                        odata1[i,j,k] = 1\n",
    "    else:\n",
    "        for i in range(s[0]):\n",
    "            for j in range(s[1]):\n",
    "                corr_map1 = data1[i,j,:,:]\n",
    "                corr_map2 = data2[i,j,:,:]\n",
    "                \n",
    "                tmp_data = np.zeros((s[2],2))\n",
    "                for k in range(s[2]):\n",
    "                    t1 = corr_map1[k,0]\n",
    "                    t2 = corr_map2[k,0]\n",
    "                    if t1*t2 > 0 and corr_map1[k,1] < float(t) and corr_map2[k,1] < float(t):\n",
    "                        odata1[i,j,k] = 1\n",
    "    \n",
    "    odata2 = np.zeros((s[0],s[2]))\n",
    "    for i in range(s[0]):\n",
    "        for j in range(s[2]):\n",
    "            tmp_data2 = odata1[i,:,j]\n",
    "            odata2[i,j] = np.sum(tmp_data2)/s[1]\n",
    "            \n",
    "    for j in range(s[2]):\n",
    "        tmp = np.round(savgol_filter(odata2[:,j],7,2),3)\n",
    "        odata2[:,j] = tmp\n",
    "            \n",
    "    return odata2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical_analysis: main function to estimate regional replicability\n",
    "### input parameters are as below:\n",
    "1. file_path is the folder which includes the npy files (The bootstrapped correlations)\n",
    "\n",
    "2. npy_file1 is the npy file from subsample1\n",
    "\n",
    "3. npy_file2 is the npy file from subsample2\n",
    "\n",
    "4. *t* indictaes the significance thresholds: p<0.05, p<0.01, fdr_p<0.05, fdr_bonferroni<0.05. For example, *t* = '0.05', '0.01','fdr','bonferroni'\n",
    "\n",
    "5. mytype indicates the imaging type: \"CSA\",\"CT\", or \"FC\"\n",
    "\n",
    "6. output_path is the folder to save the regional replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis(file_path,npy_file1,npy_file2,t,mytype,output_path):\n",
    "    files = os.listdir(file_path)\n",
    "    for f in files:\n",
    "        file_path1 = os.path.join(file_path,f) + '/' + npy_file1\n",
    "        file_path2 = os.path.join(file_path,f) + '/' + npy_file2\n",
    "        random_data1 = np.load(file_path1)\n",
    "        random_data2 = np.load(file_path2)\n",
    "\n",
    "        reliability = estimate_reliability(random_data1,random_data2,t=t)\n",
    "        if not os.path.exists(output_path+f):\n",
    "            os.mkdir(output_path+f)\n",
    "        file_name = output_path+f+'/'+mytype+'_reliability_'+t+'.csv'\n",
    "        data = pd.DataFrame(data=reliability)\n",
    "        data.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The significance level is:  0.05\n",
      "The significance level is:  0.01\n",
      "The significance level is:  fdr\n",
      "The significance level is:  bonferroni\n"
     ]
    }
   ],
   "source": [
    "# runing the function \"statistical analysis\":\n",
    "ts = ['0.05', '0.01','fdr','bonferroni']\n",
    "# input_path = \"bootstrap_ttest/split_0.5/\"\n",
    "# output_path = \"regional_replicability_ttest/split_0.5/\"\n",
    "input_path = \"boostrap_correlations/\"\n",
    "output_path = \"regional_replicability/\"\n",
    "for t in ts:\n",
    "    print(\"The significance level is: \", t)\n",
    "    statistical_analysis(input_path,\"random_data_CSA1.npy\",\"random_data_CSA2.npy\",\\\n",
    "                         t,\"CSA\",output_path)\n",
    "    statistical_analysis(input_path,\"random_data_CT1.npy\",\"random_data_CT2.npy\",\\\n",
    "                         t,\"CT\",output_path)\n",
    "    statistical_analysis(input_path,\"random_data_FC1.npy\",\"random_data_FC2.npy\",\\\n",
    "                         t,\"FC\",output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
