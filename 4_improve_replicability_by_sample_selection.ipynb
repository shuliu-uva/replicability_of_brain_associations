{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSA data\n",
    "# CSA phenotypes fields\n",
    "area_items = pd.read_csv('raw_data/Area_items.csv')\n",
    "s1 = ['eid']\n",
    "for i in range(area_items.shape[0]):\n",
    "    s1.append(str(area_items.iloc[i,0])+'-2.0')\n",
    "data1 = pd.read_csv('/dbstore/UKBiobank/Data_Download_02JULY2020/ukb42608.csv',usecols=s1)\n",
    "data1.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CT data\n",
    "# CT phenotypes fields\n",
    "thickness_items = pd.read_csv('raw_data/Thickness_items.csv')\n",
    "s2= ['eid']\n",
    "for i in range(thickness_items.shape[0]):\n",
    "    s2.append(str(thickness_items.iloc[i,0])+'-2.0')\n",
    "data2 = pd.read_csv('/dbstore/UKBiobank/Data_Download_02JULY2020/ukb42608.csv',usecols=s2)\n",
    "data2.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load functional connectivity between 21 networks\n",
    "temp_FC_data = pd.read_csv('raw_data/ukbb_FC2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global brain measures (rsfMRI head motion,total gray matter volume,ICV, total CT, average CT, scanning sites)\n",
    "global_brain_cols = ['eid','25741-2.0','25005-2.0','26521-2.0','26721-2.0','26822-2.0','26755-2.0','26856-2.0','54-2.0']\n",
    "cov1 = pd.read_csv('/dbstore/UKBiobank/Data_Download_02JULY2020/ukb42608.csv',usecols=global_brain_cols)\n",
    "cov1.dropna(how='any',inplace=True)\n",
    "# coding three scanning sites\n",
    "sites1 = []\n",
    "sites2 = []\n",
    "sites3 = []\n",
    "for i in range(cov1.shape[0]):\n",
    "    if cov1['54-2.0'].iloc[i] == 11025:\n",
    "        sites1.append(1)\n",
    "        sites2.append(0)\n",
    "        sites3.append(0)\n",
    "    if cov1['54-2.0'].iloc[i] == 11026:\n",
    "        sites1.append(0)\n",
    "        sites2.append(1)\n",
    "        sites3.append(0)\n",
    "    if cov1['54-2.0'].iloc[i] == 11027:\n",
    "        sites1.append(0)\n",
    "        sites2.append(0)\n",
    "        sites3.append(1)\n",
    "cov1['site1'] = sites1\n",
    "cov1['site2'] = sites2\n",
    "cov1['site3'] = sites3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to show the distribution of phenotypes\n",
    "def plot_distribution(variable,trait,output_path):\n",
    "    \n",
    "    plot_data = pd.DataFrame(data=variable,columns=['value'])\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    sns.displot(plot_data, x=\"value\", discrete=True)\n",
    "    plt.tick_params(direction='out', length=6, width=2,labelsize=15)\n",
    "    plt.ylabel('Count',fontsize=18)\n",
    "    plt.xlabel(trait,fontsize=18)\n",
    "    plt.vlines((Q1, Q2, Q3,), 0, plt.yticks()[0][-1], colors = (\"r\", \"black\", \"b\"),\n",
    "         linestyles = (\"solid\", \"solid\", \"solid\"))\n",
    "    final_output_path = output_path+trait+'_distribution.png'\n",
    "    plt.savefig(final_output_path,dpi=300,bbox_inches = 'tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the quartiles and show the distribution histograms\n",
    "pheno_path = 'raw_data/ukbb_phenos/'\n",
    "tmp_files = os.listdir(pheno_path)\n",
    "names = ['Fluid intelligence', 'Body mass index', 'sex','Birth month', 'Neuroticism','Alcohol consumption',\\\n",
    "         'Numeric memory', 'Age']\n",
    "for i in range(len(tmp_files)):\n",
    "    file = tmp_files[i]\n",
    "    f = file[:-4]\n",
    "    if f == 'Sex':\n",
    "        continue\n",
    "    file_path = os.path.join(pheno_path,file)\n",
    "    subjs = pd.read_csv('raw_data/ukbb_subjs/'+f+'_subjs.txt',header=None).iloc[:,0].values.tolist()\n",
    "    data = pd.read_csv(file_path).set_index('eid')\n",
    "    variable = data.loc[subjs].values[:,0]\n",
    "    \n",
    "    Q1 = np.quantile(variable,0.25)\n",
    "    Q2 = np.quantile(variable,0.5)\n",
    "    Q3 = np.quantile(variable,0.75)\n",
    "    print(f,\": \",Q2,np.sum(variable <= Q2),np.sum(variable <= Q2)/variable.shape[0])\n",
    "    print(f,\": \",Q1,Q2,Q3,np.sum(variable <= Q1),np.sum(variable <= Q1)/variable.shape[0],\\\n",
    "          np.sum(variable >= Q3),np.sum(variable >= Q3)/variable.shape[0])\n",
    "    plot_distribution(variable,names[i],'figures2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data11 = data1.set_index('eid')\n",
    "data22 = data2.set_index('eid')\n",
    "temp_FC_data2 = temp_FC_data.set_index('eid')\n",
    "cov11 = cov1.set_index('eid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a function to get the covariates\n",
    "# info1 is the matrix including global brain measures\n",
    "# info2 is the matrix including age and sex\n",
    "def get_covariates(info1,info2,cotype):\n",
    "    if cotype == 'CSA':\n",
    "        co_items = ['TCSA','site1','site2','site3']\n",
    "    if cotype == 'CT':\n",
    "        co_items = ['ACT','site1','site2','site3']\n",
    "    if cotype == 'FC':\n",
    "        co_items = ['motion','site1','site2','site3']\n",
    "    if cotype == 'pheno':\n",
    "        co_items = ['TCSA','ACT','motion','site1','site2','site3']\n",
    "    \n",
    "    info11 = info1[co_items]\n",
    "    info = pd.concat([info11,info2], axis=1,join=\"inner\")\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressing out the effects of covariates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def regression_covariant(covariant_matrix, y, standard_scale=True):\n",
    "    a = np.hstack((covariant_matrix,np.ones((covariant_matrix.shape[0], 1))))\n",
    "    w = np.linalg.lstsq(a,y,rcond=None)[0]\n",
    "\n",
    "    residual = y - covariant_matrix.dot(w[:-1])\n",
    "    residual = residual.astype('float64')\n",
    "\n",
    "    if standard_scale:\n",
    "        residual = StandardScaler().fit_transform(residual.reshape(-1,1)).flatten()\n",
    "\n",
    "    return residual, w\n",
    "\n",
    "# data is the neuroimaging measures or phenotypes\n",
    "# co is the covariates\n",
    "def regress_data(data,co):\n",
    "    codata = co.values\n",
    "    s1 = data.shape\n",
    "    reg_data = np.zeros(s1)\n",
    "    for i in range(s1[1]):\n",
    "        x = data.iloc[:,i].values\n",
    "        [rx,w1] = regression_covariant(codata,x,standard_scale=False)\n",
    "        reg_data[:,i] = rx\n",
    "    return reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a funtion to select two groups from the sample\n",
    "def split_sample(sample,split_type,Q_value):\n",
    "    if split_type == '0.5':\n",
    "        Q_value = Q_value[0]\n",
    "        sample1 = sample[sample.iloc[:,1] <= Q_value]\n",
    "        sample2 = sample[sample.iloc[:,1] > Q_value]\n",
    "    else:\n",
    "        Q_value1 = Q_value[0]\n",
    "        Q_value2 = Q_value[1]\n",
    "        sample1 = sample[sample.iloc[:,1] <= Q_value1]\n",
    "        sample2 = sample[sample.iloc[:,1] >= Q_value2]\n",
    "    \n",
    "    subjs1 = sample1['eid'].values.tolist()\n",
    "    subjs2 = sample2['eid'].values.tolist()\n",
    "    \n",
    "    return subjs1,subjs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the t statistics between high and low groups\n",
    "def bootstrap_ttest(img_data, len_sample1, len_sample2):\n",
    "    \n",
    "    img_data1 = img_data[:len_sample1,:]\n",
    "    img_data2 = img_data[len_sample1:,:]\n",
    "    \n",
    "    N = img_data.shape[1]\n",
    "    if len_sample1 < len_sample2:\n",
    "        subsampling_times = int(len_sample1/100)\n",
    "    else:\n",
    "        subsampling_times = int(len_sample2/100)\n",
    "    random_num = 100\n",
    "    \n",
    "    random_data1 = np.zeros((subsampling_times,random_num,N,2))\n",
    "    random_data2 = np.zeros((subsampling_times,random_num,N,2))\n",
    "\n",
    "    for i in range(subsampling_times):\n",
    "        print(i)\n",
    "        random_sample = 50*(i+1)\n",
    "        for j in range(random_num):\n",
    "            total_list = np.arange(len_sample1).tolist()\n",
    "            random_inds1 = random.sample(total_list,random_sample)\n",
    "            rest_total_list = list(set(total_list) - set(random_inds1))\n",
    "            random_inds2 = random.sample(rest_total_list,random_sample)\n",
    "            \n",
    "            Low_X1 = img_data1[random_inds1,:]\n",
    "            Low_X2 = img_data1[random_inds2,:]\n",
    "            \n",
    "\n",
    "            total_list = np.arange(len_sample2).tolist()\n",
    "            random_inds1 = random.sample(total_list,random_sample)\n",
    "            rest_total_list = list(set(total_list) - set(random_inds1))\n",
    "            random_inds2 = random.sample(rest_total_list,random_sample)\n",
    "            \n",
    "            High_X1 = img_data2[random_inds1,:]\n",
    "            High_X2 = img_data2[random_inds2,:]\n",
    "            \n",
    "\n",
    "            for k in range(N):\n",
    "                t1,p1 = ttest_ind(High_X1[:,k],Low_X1[:,k])\n",
    "                t2,p2 = ttest_ind(High_X2[:,k],Low_X2[:,k])\n",
    "                random_data1[i,j,k,0] = t1\n",
    "                random_data1[i,j,k,1] = p1\n",
    "                random_data2[i,j,k,0] = t2\n",
    "                random_data2[i,j,k,1] = p2\n",
    "     \n",
    "    return random_data1,random_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The quartiles that can be used to split the sample\n",
    "files = ['IQ','BMI','NS','alcohol','NM','Age']\n",
    "Q1_values = [5, 23.46, 0, 2, 6, 57]\n",
    "Q2_values = [6, 25.84, 2, 5, 6, 64]\n",
    "Q3_values = [8, 28.75, 6, 11, 8, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_type = '0.25' (Quartiles) or '0.5' (median values)\n",
    "split_type = \"0.25\"\n",
    "\n",
    "# create an empty folder to save results\n",
    "if not os.path.exists('bootstrap_ttest/'+\"split_\"+split_type):\n",
    "        os.mkdir('bootstrap_ttest/'+\"split_\"+split_type)\n",
    "empty_path = 'bootstrap_ttest/'+\"split_\"+split_type\n",
    "\n",
    "\n",
    "for i in range(len(files)):\n",
    "    f = files[i]\n",
    "    print(f)\n",
    "    pheno_path = 'raw_data/ukbb_phenos/'\n",
    "    pheno = pd.read_csv(os.path.join(pheno_path,f+'.csv'))\n",
    "\n",
    "    # get information about age ,sex\n",
    "    if f == 'Age':\n",
    "        cov2 = pd.read_csv('raw_data/Sex.csv')\n",
    "    else:\n",
    "        Sex = pd.read_csv('raw_data/Sex.csv').set_index('eid')\n",
    "        Age = pd.read_csv('raw_data/ukbb_phenos/Age.csv').set_index('eid')\n",
    "        cov2 = pd.concat([Age,Sex], axis=1,join=\"inner\").reset_index() \n",
    "        \n",
    "    cov22 = cov2.set_index('eid')\n",
    "    pheno2 = pheno.set_index('eid')\n",
    "    subjs = pd.read_csv('raw_data/ukbb_subjs/'+f+'_subjs.txt',header=None).iloc[:,0].values.tolist()\n",
    "    pheno3 = pheno2.loc[subjs].reset_index()\n",
    "    \n",
    "    # use function \"split_sample\" to get the subjects of two subsamples\n",
    "    if split_type == \"0.5\":\n",
    "        Q = [Q2_values[i]]\n",
    "    else:\n",
    "        Q = [Q1_values[i],Q3_values[i]]\n",
    "        \n",
    "    l1,l2 = split_sample(pheno3,split_type,Q)\n",
    "    l = l1 + l2\n",
    "    print(\"sample1 size: \",len(l1)/len(subjs),\"sample2 size: \", len(l2)/len(subjs))\n",
    "    \n",
    "    CSA_data = data11.loc[l]\n",
    "    CT_data = data22.loc[l]\n",
    "    FC_data = temp_FC_data2.loc[l]\n",
    "    global_data = cov11.loc[l]\n",
    "    age_and_sex = cov22.loc[l]\n",
    "    \n",
    "    # transfer the column names of global brain measures\n",
    "    global_data2 = pd.DataFrame({\"eid\" : global_data.index})\n",
    "    global_data2['motion'] = global_data['25741-2.0'].values\n",
    "    global_data2['TCSA'] = global_data['26721-2.0'].values + global_data['26822-2.0'].values\n",
    "    global_data2['ACT'] = global_data['26755-2.0'].values + global_data['26856-2.0'].values\n",
    "    global_data2['site1'] = global_data['site1'].values\n",
    "    global_data2['site2'] = global_data['site2'].values\n",
    "    global_data2['site3'] = global_data['site3'].values\n",
    "    global_data2.set_index('eid',inplace=True)\n",
    "    \n",
    "    # regress out the covariates for brain measures and the variable\n",
    "    CSA_co = get_covariates(global_data2,age_and_sex,'CSA')\n",
    "    reg_CSA_data = regress_data(CSA_data,CSA_co)\n",
    "\n",
    "    CT_co = get_covariates(global_data2,age_and_sex,'CT')\n",
    "    reg_CT_data = regress_data(CT_data,CT_co)\n",
    "\n",
    "    FC_co = get_covariates(global_data2,age_and_sex,'FC')\n",
    "    reg_FC_data = regress_data(FC_data,FC_co)\n",
    "    \n",
    "    random_data_CSA1,random_data_CSA2 = bootstrap_ttest(reg_CSA_data,len(l1),len(l2))\n",
    "    random_data_CT1,random_data_CT2 = bootstrap_ttest(reg_CT_data,len(l1),len(l2))\n",
    "    random_data_FC1,random_data_FC2 = bootstrap_ttest(reg_FC_data,len(l1),len(l2))\n",
    "    \n",
    "    if not os.path.exists(empty_path+'/'+f):\n",
    "        os.mkdir(empty_path+'/'+f)\n",
    "    save_path = empty_path+'/'+f\n",
    "    CSA_file_name1 = save_path+'/random_data_CSA1.npy'\n",
    "    CSA_file_name2 = save_path+'/random_data_CSA2.npy'\n",
    "    CT_file_name1 = save_path+'/random_data_CT1.npy'\n",
    "    CT_file_name2 = save_path+'/random_data_CT2.npy'\n",
    "    FC_file_name1 = save_path+'/random_data_FC1.npy'\n",
    "    FC_file_name2 = save_path+'/random_data_FC2.npy'\n",
    "\n",
    "    np.save(CSA_file_name1,random_data_CSA1)\n",
    "    np.save(CSA_file_name2,random_data_CSA2)\n",
    "    np.save(CT_file_name1,random_data_CT1)\n",
    "    np.save(CT_file_name2,random_data_CT2)\n",
    "    np.save(FC_file_name1,random_data_FC1)\n",
    "    np.save(FC_file_name2,random_data_FC2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
